"""
src/ingest.py
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Ingestion Pipeline (–ï—Ç–∞–ø 1):
  PDF-—Ñ–∞–π–ª–∏ ‚Üí Chunks –∑ –º–µ—Ç–∞–¥–∞–Ω–∏–º–∏ ‚Üí Embeddings ‚Üí ChromaDB

–ó–∞–ø—É—Å–∫:
    python -m src.ingest
    # –∞–±–æ –∑ –∫–∞—Å—Ç–æ–º–Ω–æ—é —Ç–µ—á–µ–Ω–æ—é:
    python -m src.ingest --pdf_dir data/raw --db_dir data/chromadb
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
"""

import argparse
import logging
import os
import sys
from pathlib import Path

from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

load_dotenv()

# –†–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ–π (–≤—ñ–¥–Ω–æ—Å–Ω–æ –∫–æ—Ä–µ–Ω—è –ø—Ä–æ–µ–∫—Ç—É)
PROJECT_ROOT = Path(__file__).resolve().parent.parent
DEFAULT_PDF_DIR = PROJECT_ROOT / "data" / "raw"
DEFAULT_DB_DIR  = PROJECT_ROOT / "data" / "chromadb"

# –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ —á–∞–Ω–∫—ñ–Ω–≥—É (–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ Design Doc)
CHUNK_SIZE    = 900   # —Å–∏–º–≤–æ–ª—ñ–≤ ‚Äî –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ª–æ–≥—ñ—á–Ω–æ–≥–æ –±–ª–æ–∫—É —Ç–∞—Ä–∏—Ñ—ñ–≤
CHUNK_OVERLAP = 200   # —Å–∏–º–≤–æ–ª—ñ–≤ ‚Äî –Ω–µ –¥–∞—î–º–æ —Ä–æ–∑—Ä–∏–≤–∞—Ç–∏ —Ä–µ—á–µ–Ω–Ω—è / —Ä—è–¥–∫–∏ —Ç–∞–±–ª–∏—Ü—å

# –ú—É–ª—å—Ç–∏–ª—ñ–Ω–≥–≤–∞–ª—å–Ω–∞ embedding-–º–æ–¥–µ–ª—å (–ø—ñ–¥—Ç—Ä–∏–º—É—î —É–∫—Ä–∞—ó–Ω—Å—å–∫—É, –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–∞)
EMBEDDING_MODEL = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"

# –ù–∞–∑–≤–∞ –∫–æ–ª–µ–∫—Ü—ñ—ó —É ChromaDB
CHROMA_COLLECTION = "finrag_tariffs"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-8s | %(message)s",
    datefmt="%H:%M:%S",
)
log = logging.getLogger(__name__)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def load_pdfs(pdf_dir: Path) -> list[Document]:
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –≤—Å—ñ PDF –∑ –∑–∞–∑–Ω–∞—á–µ–Ω–æ—ó –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó.
    –î–æ–¥–∞—î –¥–æ –º–µ—Ç–∞–¥–∞–Ω–∏—Ö: source (—ñ–º'—è —Ñ–∞–π–ª—É) —Ç–∞ page (–Ω–æ–º–µ—Ä —Å—Ç–æ—Ä—ñ–Ω–∫–∏).
    –ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –æ–±'—î–∫—Ç—ñ–≤ Document.
    """
    if not pdf_dir.exists():
        log.error("–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –∑ PDF –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞: %s", pdf_dir)
        sys.exit(1)

    pdf_files = list(pdf_dir.glob("*.pdf"))

    if not pdf_files:
        log.warning(
            "–£ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó '%s' –Ω–µ–º–∞—î PDF-—Ñ–∞–π–ª—ñ–≤.\n"
            "‚Üí –ü–æ–∫–ª–∞–¥–∏ —Ö–æ—á–∞ –± –æ–¥–∏–Ω .pdf-—Ñ–∞–π–ª —É data/raw/ —ñ –∑–∞–ø—É—Å—Ç–∏ —Å–∫—Ä–∏–ø—Ç –∑–Ω–æ–≤—É.",
            pdf_dir,
        )
        sys.exit(0)

    all_docs: list[Document] = []

    for pdf_path in pdf_files:
        log.info("üìÑ  –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: %s", pdf_path.name)
        try:
            loader = PyPDFLoader(str(pdf_path))
            docs = loader.load()  # –∫–æ–∂–µ–Ω –µ–ª–µ–º–µ–Ω—Ç = –æ–¥–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ PDF

            # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ –º–µ—Ç–∞–¥–∞–Ω—ñ ‚Äî –∑–∞–ª–∏—à–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ —Ç–µ, —â–æ –Ω–∞–º –ø–æ—Ç—Ä—ñ–±–Ω–æ
            for doc in docs:
                doc.metadata = {
                    "source": pdf_path.name,          # –Ω–∞–ø—Ä. "Tariff_Credit_Card.pdf"
                    "page":   doc.metadata.get("page", 0) + 1,  # 1-indexed
                }

            all_docs.extend(docs)
            log.info("   ‚úî –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —Å—Ç–æ—Ä—ñ–Ω–æ–∫: %d", len(docs))

        except Exception as exc:
            log.error("   ‚úò –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ %s: %s", pdf_path.name, exc)

    log.info("‚îÄ" * 50)
    log.info("–í—Å—å–æ–≥–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —Å—Ç–æ—Ä—ñ–Ω–æ–∫: %d –∑ %d PDF-—Ñ–∞–π–ª—ñ–≤", len(all_docs), len(pdf_files))
    return all_docs


def split_documents(docs: list[Document]) -> list[Document]:
    """
    –†–æ–∑–±–∏–≤–∞—î –¥–æ–∫—É–º–µ–Ω—Ç–∏ –Ω–∞ —á–∞–Ω–∫–∏ –∑–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—î—é –∑ Design Doc:
    - size=900 / overlap=200
    - –ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç —Ä–æ–∑–±–∏—Ç—Ç—è: –∞–±–∑–∞—Ü–∏ ‚Üí —Ä—è–¥–∫–∏ ‚Üí —Ä–µ—á–µ–Ω–Ω—è
    - –ó–±–µ—Ä—ñ–≥–∞—î –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –º–µ—Ç–∞–¥–∞–Ω—ñ (source, page) —É –∫–æ–∂–Ω–æ–º—É —á–∞–Ω–∫—É
    """
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", ". ", "! ", "? ", " ", ""],
        length_function=len,
        add_start_index=True,   # –¥–æ–¥–∞—î –ø–æ–∑–∏—Ü—ñ—é –ø–æ—á–∞—Ç–∫—É —á–∞–Ω–∫—É –≤ –º–µ—Ç–∞–¥–∞–Ω—ñ
    )

    chunks = splitter.split_documents(docs)

    log.info(
        "–ß–∞–Ω–∫—ñ–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: %d —Å—Ç–æ—Ä—ñ–Ω–æ–∫ ‚Üí %d —á–∞–Ω–∫—ñ–≤ (size=%d, overlap=%d)",
        len(docs), len(chunks), CHUNK_SIZE, CHUNK_OVERLAP,
    )

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª—è –¥–µ–±–∞–≥—É
    if chunks:
        sizes = [len(c.page_content) for c in chunks]
        log.info(
            "–†–æ–∑–º—ñ—Ä–∏ —á–∞–Ω–∫—ñ–≤: –º—ñ–Ω=%d, –º–∞–∫—Å=%d, —Å–µ—Ä–µ–¥–Ω—ñ–π=%d —Å–∏–º–≤–æ–ª—ñ–≤",
            min(sizes), max(sizes), int(sum(sizes) / len(sizes)),
        )

    return chunks


def build_vector_store(chunks: list[Document], db_dir: Path) -> Chroma:
    """
    –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î –ª–æ–∫–∞–ª—å–Ω—É ChromaDB —ñ –∑–±–µ—Ä—ñ–≥–∞—î –≤–µ–∫—Ç–æ—Ä–∏.
    –ó–∞–≤–∂–¥–∏ –æ—á–∏—â—É—î —Å—Ç–∞—Ä—É –∫–æ–ª–µ–∫—Ü—ñ—é –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å–æ–º ‚Äî –∑–∞–ø–æ–±—ñ–≥–∞—î –¥—É–±–ª—ñ–∫–∞—Ç–∞–º.
    """
    db_dir.mkdir(parents=True, exist_ok=True)

    log.info("–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è embedding-–º–æ–¥–µ–ª—ñ: %s", EMBEDDING_MODEL)
    log.info("    (–ü–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫ –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ 1-2 —Ö–≤–∏–ª–∏–Ω–∏)")

    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={"device": "cpu"},
        encode_kwargs={"normalize_embeddings": True},
    )

    # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—É –∫–æ–ª–µ–∫—Ü—ñ—é —è–∫—â–æ –≤–æ–Ω–∞ —î ‚Äî –∑–∞–ø–æ–±—ñ–≥–∞—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∞–º
    try:
        import chromadb
        client = chromadb.PersistentClient(path=str(db_dir))
        existing = [c.name for c in client.list_collections()]
        if CHROMA_COLLECTION in existing:
            client.delete_collection(CHROMA_COLLECTION)
            log.info("–°—Ç–∞—Ä—É –∫–æ–ª–µ–∫—Ü—ñ—é '%s' –≤–∏–¥–∞–ª–µ–Ω–æ", CHROMA_COLLECTION)
    except Exception as e:
        log.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–¥–∞–ª–∏—Ç–∏ —Å—Ç–∞—Ä—É –∫–æ–ª–µ–∫—Ü—ñ—é: %s", e)

    log.info("–ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è %d —á–∞–Ω–∫—ñ–≤ —É ChromaDB: %s", len(chunks), db_dir)

    vector_store = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        collection_name=CHROMA_COLLECTION,
        persist_directory=str(db_dir),
    )

    count = vector_store._collection.count()
    log.info("ChromaDB –≥–æ—Ç–æ–≤–∞. –ó–±–µ—Ä–µ–∂–µ–Ω–æ –≤–µ–∫—Ç–æ—Ä—ñ–≤: %d", count)

    return vector_store


def verify_store(vector_store: Chroma) -> None:
    """
    –®–≤–∏–¥–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞: –≤–∏–∫–æ–Ω—É—î –æ–¥–∏–Ω —Ç–µ—Å—Ç–æ–≤–∏–π –∑–∞–ø–∏—Ç –¥–æ –±–∞–∑–∏
    —ñ –≤–∏–≤–æ–¥–∏—Ç—å –Ω–∞–π—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—à–∏–π —á–∞–Ω–∫.
    """
    test_query = "–∫–æ–º—ñ—Å—ñ—è –∑–∞ –∑–Ω—è—Ç—Ç—è –≥–æ—Ç—ñ–≤–∫–∏"
    log.info("‚îÄ" * 50)
    log.info("üîç  –¢–µ—Å—Ç–æ–≤–∏–π –ø–æ—à—É–∫: '%s'", test_query)

    results = vector_store.similarity_search(test_query, k=2)

    if not results:
        log.warning("   –ù—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ü–µ—Ä–µ–≤—ñ—Ä, —á–∏ PDF –º—ñ—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç (–Ω–µ —Å–∫–∞–Ω).")
        return

    for i, doc in enumerate(results, 1):
        meta = doc.metadata
        preview = doc.page_content[:200].replace("\n", " ")
        log.info(
            "   [%d] %s, —Å—Ç–æ—Ä. %s | ¬´%s...¬ª",
            i, meta.get("source"), meta.get("page"), preview,
        )


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –¢–æ—á–∫–∞ –≤—Ö–æ–¥—É
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def run_ingestion(pdf_dir: Path, db_dir: Path) -> None:
    """–ì–æ–ª–æ–≤–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω —ñ–Ω–≥–µ—Å—Ç—ñ—ó."""
    log.info("=" * 50)
    log.info("üöÄ  FinRAG Ingestion Pipeline ‚Äî —Å—Ç–∞—Ä—Ç")
    log.info("   PDF:    %s", pdf_dir)
    log.info("   DB:     %s", db_dir)
    log.info("=" * 50)

    # –ö—Ä–æ–∫ 1: –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ PDF
    docs = load_pdfs(pdf_dir)

    # –ö—Ä–æ–∫ 2: –†–æ–∑–±–∏—Ç–∏ –Ω–∞ —á–∞–Ω–∫–∏
    chunks = split_documents(docs)

    # –ö—Ä–æ–∫ 3: –ó–±–µ—Ä–µ–≥—Ç–∏ —É ChromaDB
    vector_store = build_vector_store(chunks, db_dir)

    # –ö—Ä–æ–∫ 4: –í–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—è
    verify_store(vector_store)

    log.info("=" * 50)
    log.info("üéâ  Ingestion –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")
    log.info("   –î–∞–ª—ñ: –∑–∞–ø—É—Å—Ç–∏ –ï—Ç–∞–ø 2 ‚Äî src/retrieval.py")
    log.info("=" * 50)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="FinRAG ‚Äî Ingestion Pipeline: PDF ‚Üí ChromaDB"
    )
    parser.add_argument(
        "--pdf_dir",
        type=Path,
        default=DEFAULT_PDF_DIR,
        help=f"–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –∑ PDF-—Ñ–∞–π–ª–∞–º–∏ (–∑–∞ –∑–∞–º–æ–≤—á.: {DEFAULT_PDF_DIR})",
    )
    parser.add_argument(
        "--db_dir",
        type=Path,
        default=DEFAULT_DB_DIR,
        help=f"–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—è –¥–ª—è ChromaDB (–∑–∞ –∑–∞–º–æ–≤—á.: {DEFAULT_DB_DIR})",
    )
    args = parser.parse_args()
    run_ingestion(args.pdf_dir, args.db_dir)
